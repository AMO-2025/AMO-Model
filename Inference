from torchvision.models import efficientnet_b0
from PIL import Image
import torch.nn.functional as F

# getting initial class 
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = efficientnet_b0(pretrained=True)

# dropout + redefine class 
model.classifier = nn.Sequential(
    nn.Dropout(0.5),
    nn.Linear(model.classifier[1].in_features, 7)
)

# preprocessing 
train_transforms = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(30),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

val_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

model.load_state_dict(torch.load('./weight/efficient_dartmouth_final.pth', map_location=device))
model = model.to(device)
emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprised']

def final_emotion(image_path, model, transform, device):
    image = Image.open(image_path).convert('RGB')
    input_tensor = transform(image).unsqueeze(0).to(device)
    
    model.eval()
    with torch.no_grad():
        output = model(input_tensor)
        probs = F.softmax(output, dim=1)
        pred_idx = torch.argmax(probs, dim=1).item()
        pred_label = emotion_labels[pred_idx]
        confidence = probs[0][pred_idx].item()
    
    return pred_label, confidence
    
test_image_path = 'write_your_filename'
label, prob = final_emotion(test_image_path, model, val_transforms, device)
print(f"Predicted emotion: {label} ({prob*100:.2f}%)")
